{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SeaSoar Processing\n",
    "\n",
    "1. Load data\n",
    "2. Identify upcasts and downcasts\n",
    "3. Flag spurious pressure/data points by moving median filter\n",
    "4. Bin sensor data to regular pressures\n",
    "5. Flag outliers in signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T19:50:00.423822Z",
     "start_time": "2018-02-05T19:49:58.664Z"
    },
    "cell_style": "center"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages Loaded:\n",
      "ncdf4 R.matlab openxlsx RColorBrewer compiler lattice geosphere readxl data.table rworldmap rworldxtra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: ncdf4\n",
      "Loading required package: R.matlab\n",
      "R.matlab v3.6.1 (2016-10-19) successfully loaded. See ?R.matlab for help.\n",
      "\n",
      "Attaching package: ‘R.matlab’\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    getOption, isOpen\n",
      "\n",
      "Loading required package: openxlsx\n",
      "Loading required package: RColorBrewer\n",
      "Loading required package: compiler\n",
      "Loading required package: lattice\n",
      "Loading required package: geosphere\n",
      "Loading required package: readxl\n",
      "Loading required package: data.table\n",
      "Loading required package: rworldmap\n",
      "Loading required package: sp\n",
      "Error: package or namespace load failed for ‘rworldmap’ in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):\n",
      " there is no package called ‘fields’\n",
      "Loading required package: rworldxtra\n"
     ]
    }
   ],
   "source": [
    "source('source.r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T19:50:00.928488Z",
     "start_time": "2018-02-05T19:50:00.812Z"
    },
    "cell_style": "center"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "46"
      ],
      "text/latex": [
       "46"
      ],
      "text/markdown": [
       "46"
      ],
      "text/plain": [
       "[1] 46"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input.dir = '../../Models/SeaSoar/SeaSoar2/'\n",
    "\n",
    "files = list.files(input.dir, full.names = TRUE)\n",
    "files = files[grepl('.mat', files)]\n",
    "files = files[!grepl('.rdata', files)]\n",
    "length(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " chr [1:46] \"../../Models/SeaSoar/SeaSoar2//FLT_DAT001.mat\" ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "'../../Models/SeaSoar/SeaSoar2//FLT_DAT001.mat'"
      ],
      "text/latex": [
       "'../../Models/SeaSoar/SeaSoar2//FLT\\_DAT001.mat'"
      ],
      "text/markdown": [
       "'../../Models/SeaSoar/SeaSoar2//FLT_DAT001.mat'"
      ],
      "text/plain": [
       "[1] \"../../Models/SeaSoar/SeaSoar2//FLT_DAT001.mat\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "str(files)\n",
    "files[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T19:50:07.324717Z",
     "start_time": "2018-02-05T19:50:07.142Z"
    }
   },
   "outputs": [],
   "source": [
    "get.data = function(input.dir, file) {\n",
    "    data = readMat(paste0(input.dir, file), fixNames = TRUE)\n",
    "    names = unlist(dimnames(data$data)[1])\n",
    "\n",
    "    ## Partition up datea\n",
    "    eng = as.data.frame(data$data[2:12])\n",
    "    sensor = as.data.frame(data$data[13:36])\n",
    "    colnames(sensor) = names[13:36]\n",
    "    colnames(eng) = names[2:12]\n",
    "    \n",
    "    sensor$time = seq(from = eng$time[1], by = 1/24, length.out = nrow(sensor))\n",
    "    \n",
    "    return(list(eng = eng, sensor = sensor))\n",
    "}\n",
    "\n",
    "#### Flag Outliers in pressure\n",
    "flag.p.outliers = function(data, dp = 0.5, verbose = TRUE, window = 25) {\n",
    "    l = which(abs(data$sensor$p - runmed(data$sensor$p, window)) > dp)\n",
    "    \n",
    "    data$sensor$p.FLAG = 1 # keep\n",
    "    data$sensor$p.FLAG[l] = 3 # reject\n",
    "    \n",
    "    if (verbose) {\n",
    "        n = length(l)\n",
    "        perc = floor(length(l) / nrow(data$sensor)*1000)/10\n",
    "        \n",
    "        print(paste0('Flagging identified ', n, ' (', perc, '%) outliers.'))\n",
    "    }\n",
    "    data\n",
    "}\n",
    "\n",
    "#### Bin Data by pressure and time\n",
    "bin.pt = function(data, dp = 1, secs = 10) {\n",
    "    i = 1\n",
    "    while (i < nrow(data$sensor)) {\n",
    "        l = which(abs(data$sensor$p - data$sensor$p[i]) + abs(data$sensor$time - data$sensor$time[i]) / secs < dp / 2 &\n",
    "                 data$sensor$p.FLAG == 1)\n",
    "        temp = apply(data$sensor[l,], 2, function(x) {mean(x, na.rm = TRUE)})\n",
    "        \n",
    "        if (length(l) > 1) {\n",
    "            data$sensor[i,] = temp\n",
    "            l = l[l != i]\n",
    "            \n",
    "            data$sensor = data$sensor[-l,]\n",
    "        }\n",
    "        i = i + 1\n",
    "    }\n",
    "    \n",
    "    data\n",
    "}\n",
    "\n",
    "#### Bin Data by pressure\n",
    "bin.p = function(data, dp = 1) {\n",
    "    data$sensor = data$sensor[which(data$sensor$p.FLAG == 1),]\n",
    "    data$sensor$p = floor((data$sensor$p + 0.5) / dp)\n",
    "    data$sensor$n.bin = 1\n",
    "    \n",
    "    i = 1\n",
    "    while (i < nrow(data$sensor)) {\n",
    "        delta.p = abs(diff(data$sensor$p[i:nrow(data$sensor)]))  # i refenced\n",
    "        \n",
    "        ## Find entries to average across\n",
    "        l = which(cumsum(delta.p) == 0)\n",
    "        l = c(i, l + i)\n",
    "        \n",
    "        temp = as.numeric(apply(data$sensor[l,], 2, function(x) {median(x, na.rm = TRUE)}))\n",
    "        \n",
    "        ## Update values and some housekepping\n",
    "        if (length(l) > 1 & length(temp) == ncol(data$sensor)) { ## Need to update values\n",
    "            data$sensor[i,] = temp\n",
    "            data$sensor$n.bin[i] = length(l)\n",
    "            \n",
    "            l = l[l != i]\n",
    "            data$sensor = data$sensor[-l,] ## Remove other values\n",
    "            delta.p = delta.p[-l]\n",
    "        }\n",
    "        i = i + 1\n",
    "    }\n",
    "    ## Finalize and return averaged data\n",
    "    data$sensor$p = data$sensor$p * dp\n",
    "    data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T19:50:51.534380Z",
     "start_time": "2018-02-05T19:50:51.510Z"
    }
   },
   "outputs": [],
   "source": [
    "check.bin = function(data, l = c(0000:135000)) {\n",
    "    plot(data$sensor$time[l], data$sensor$p[l], type='l', ylab='Pressure', xlab='Time', ylim=c(100,0), yaxs='i')\n",
    "    points(bin.data$sensor$time, bin.data$sensor$p, pch=4, cex=1.5, col='blue')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T19:50:59.746394Z",
     "start_time": "2018-02-05T19:50:59.718Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocess.files = function(input.dir, files, verbose = FALSE) {\n",
    "    for (f in 1:length(files)) {\n",
    "        if (verbose) {\n",
    "            print(paste0('Starting file: ', files[f], ' (', f, ' of ', length(files), ')'))\n",
    "        }\n",
    "        \n",
    "        data = get.data(input.dir, files[f])\n",
    "        data = flag.p.outliers(data)\n",
    "        n.before = nrow(data$sensor)\n",
    "        \n",
    "        if (verbose) {print('Binning the data.')}\n",
    "        data = bin.p(data)\n",
    "        \n",
    "        if (verbose) {print('Checkpoint Saved.')}\n",
    "        if (verbose) {print('')}\n",
    "        \n",
    "        save(data, file = paste0('RStates/SeaSoar/Seasoar2-binned-', files[f], '.rdata'))\n",
    "        \n",
    "        if (verbose) {\n",
    "            print(paste0('Number of Sensor Records before binning: ', n.before))\n",
    "            print(paste0('Number of Sensor Records after binning: ', nrow(data$sensor)))\n",
    "            print(paste0('(', floor(nrow(data$sensor)/n.before * 1000) / 10, '%)'))\n",
    "        }\n",
    "        print('')\n",
    "    }\n",
    "}\n",
    "\n",
    "load.rstate = function(input.dir, files, verbose = TRUE) {\n",
    "    compiled.data = NULL\n",
    "    \n",
    "    for (f in 1:length(files)) {\n",
    "        if (verbose) {print(paste0('Starting file: ', files[f], ' (', f, ' of ', length(files), ')'))}\n",
    "        load(file = paste0('RStates/SeaSoar/Seasoar2-binned-', files[f], '.rdata'))\n",
    "        \n",
    "        if (is.null(compiled.data)) {\n",
    "            compiled.data = data\n",
    "        } else {\n",
    "            compiled.data$sensor = rbind(compiled.data$sensor, data$sensor)\n",
    "            compiled.data$eng = rbind(compiled.data$eng, data$eng)\n",
    "        }\n",
    "        print(nrow(data$sensor))\n",
    "    }\n",
    "    compiled.data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T21:16:34.245848Z",
     "start_time": "2018-01-30T21:56:10.483Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#preprocess.files(input.dir, files, verbose = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = load.rstate(input.dir, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.time = function(x, tz = 'UTC') {\n",
    "    as.POSIXct(x, origin=\"1970-01-01\", tz = tz)\n",
    "}\n",
    "\n",
    "add.times = function(data, tz = 'UTC') {\n",
    "    data$sensor$time.real = as.POSIXct(data$sensor$time, origin=\"1970-01-01\", tz = tz)\n",
    "    data$eng$time.real = as.POSIXct(data$eng$time, origin=\"1970-01-01\", tz = tz)\n",
    "    \n",
    "    data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i in 1:ncol(data$sensor)) {\n",
    "    data$sensor[,i] = as.numeric(data$sensor[,i])\n",
    "}\n",
    "str(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = add.times(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add.direction = function(data, p.min = 8, p.max = 250) {\n",
    "    ## value codes\n",
    "    ##   -1 = downcast\n",
    "    ##   +1 = upcast\n",
    "    ##    0 = ambiguous/outside bounds\n",
    "    \n",
    "    data$sensor$direction = 0\n",
    "    dp = diff(data$sensor$p)\n",
    "    \n",
    "    l = which(dp < 0) # getting shallower\n",
    "    data$sensor$direction[l+1] = 1\n",
    "    \n",
    "    l = which(dp > 0) # getting depper\n",
    "    data$sensor$direction[l+1] = -1\n",
    "    \n",
    "    data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = add.direction(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T21:36:43.303791Z",
     "start_time": "2018-01-31T21:36:41.783Z"
    }
   },
   "outputs": [],
   "source": [
    "get.mld = function(data, rho = 0.1) {\n",
    "    mld = data.frame(time = 0, lat = 0, lon = 0, mld = 0, stringsAsFactors = FALSE)\n",
    "    \n",
    "    ## Trim data to between 5db and 100db\n",
    "    data$sensor = data$sensor[data$sensor$p > 5 & data$sensor$p < 100,]\n",
    "    \n",
    "    ## Find all the 10meter points on the downcast\n",
    "    l = which(data$sensor$p == 10 & data$sensor$direction == -1)\n",
    "    \n",
    "    ## l should only include entries from different casts: here 10 minutes apart.\n",
    "    dt = as.numeric(difftime(data$sensor$time.real[l], data$sensor$time.real[l[1]], units='mins'))\n",
    "    l = l[c(1, which(diff(dt) > 10))]\n",
    "    \n",
    "    print(length(l))\n",
    "    \n",
    "    ## calculate mld and add to dataframe\n",
    "    for (i in 1:length(l)) {\n",
    "        t.10 = data$sensor$time.real[l[i]]\n",
    "        rho.10 = data$sensor$sigma2[l[i]]\n",
    "        \n",
    "        ## define cast as within 3 minutes, downcast, pressure > 10, and afterwards\n",
    "        l.time = which(as.numeric(difftime(data$sensor$time.real, t.10, unit='mins')) < 5 &\n",
    "                       data$sensor$direction == -1 & data$sensor$p > 10 &\n",
    "                       as.numeric(difftime(data$sensor$time.real, t.10, unit='mins')) > 0)\n",
    "        \n",
    "        if (length(l.time) > 15) {\n",
    "            l.mld = min(which(data$sensor$sigma2[l.time] > rho.10 + rho))\n",
    "            t.mld = data$sensor$time.real[l.time[l.mld]]\n",
    "\n",
    "            eng = which.min(as.numeric(difftime(data$eng$time.real, t.10, units = 'mins'))^2)\n",
    "            mld = rbind(mld, c(t.mld, data$eng$lat[eng], data$eng$lon[eng], data$sensor$p[l.time[l.mld]]))\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    mld = mld[-1,]\n",
    "    mld$time = conv.time(mld$time)\n",
    "    mld\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mld = get.mld(data, 0.1)\n",
    "mld2 = get.mld(data, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot(data$sensor$time.real, data$sensor$p, cex=0.1, pch=20, col=get.qual.pal(3)[data$sensor$direction+2],\n",
    "#     ylim=c(300,0), yaxs='i', ylab='Depth', xlab='')\n",
    "plot(data$sensor$time.real[c(1, nrow(data$sensor))], data$sensor$p[c(1, nrow(data$sensor))], cex=0.1, pch=20, col='white',\n",
    "     ylim=c(100,0), yaxs='i', ylab='Depth', xlab='')\n",
    "\n",
    "points(mld$time, mld$mld, pch=15, col='dark red')\n",
    "points(mld2$time, mld2$mld, pch=16, col='dark blue', cex=0.5)\n",
    "lines(c(min(mld$time), max(mld$time)), c(10,10), lty=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.map(lon = mld$lon, lat = mld$lat, main = 'SeaSoar MLDs', col = make.div.pal(mld$mld, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasoar2 = mld\n",
    "save(seasoar2, file = 'RStates/SeaSoar2.MLD (0.1).rdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(data, file='RStates/SeaSoar2.final.rdata')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.mld = function(mld, i, window = 3) {\n",
    "    l = which(as.numeric(difftime(data$sensor$time.real, mld$time[i], units = 'mins')) < window &\n",
    "              as.numeric(difftime(data$sensor$time.real, mld$time[i], units = 'mins')) >= -window &\n",
    "             data$sensor$direction == -1)\n",
    "    \n",
    "    plot(data$sensor$sigma2[l], data$sensor$p[l], ylim=c(100,0), xlim=c(1023,1027), yaxs='i',\n",
    "         pch=20, col='#00000050', cex=1, main=paste0(i, ' - ', length(l)), ylab='Depth', xlab='Density')\n",
    "    \n",
    "    lines(c(0,10000), rep(mld$mld[i], 2), lty=2, col='red')\n",
    "    #lines(c(0,10000), rep(mld2$mld[i], 2), lty=1, col='red')\n",
    "    lines(c(0,10000), rep(10, 2), lty=2, col='blue')\n",
    "    \n",
    "    text(1023, 80, mld$mld[i])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pdf('Output/SeaSoar2 - MLD Review (0.2).pdf')\n",
    "\n",
    "par(mfrow=c(2,2))\n",
    "for(i in 1:nrow(mld2)) {\n",
    "    plot.mld(mld2, i)\n",
    "}\n",
    "\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
